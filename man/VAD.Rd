% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/vad.R
\name{VAD}
\alias{VAD}
\title{Voice Activity Detection}
\usage{
VAD(
  file,
  mode = c("normal", "lowbitrate", "aggressive", "veryaggressive"),
  milliseconds = 10L,
  type = "webrtc"
)
}
\arguments{
\item{file}{the path to an audio file which should be a file in 16 bit with mono PCM samples (pcm_s16le codec) with a sampling rate of either 8Khz, 16KHz or 32Khz}

\item{mode}{character string with the type of voice detection, either 'normal', 'lowbitrate', 'aggressive' or 'veryaggressive' where 'veryaggressive' means more silences are detected}

\item{milliseconds}{integer with the number of milliseconds indicating to compute by this number of milliseconds the VAD signal. Can only be 10, 20 or 30. Defaults to 10.}

\item{type}{character string with the type of VAD model. Only 'webrtc' currently.}
}
\value{
an objec of class \code{VAD} which is a list with elements
\itemize{
\item{file: the path to the file}
\item{sample_rate: the sample rate of the audio file in Hz}
\item{channels: the number of channels in the audio - as the algorithm requires the audio to be mono this should only be 1}
\item{samples: the number of samples in the data}
\item{bitsPerSample: the number of bits per sample}
\item{bytesPerSample: the number of bytes per sample}
\item{type: the type of VAD model - currently only 'webrtc-gmm'}
\item{mode: the provided VAD mode}
\item{milliseconds: the provided milliseconds - either by 10, 20 or 30 ms frames}
\item{frame_length: the frame length corresponding to the provided milliseconds}
\item{vad: a data.frame with columns millisecond, has_voice and vad_segment indicating if the audio contains an active voice signal at that millisecond}
\item{vad_segments: a data.frame with columns vad_segment, start, end and has_voice where the start/end values are in seconds}
\item{vad_stats: a list with elements n_segments, n_segments_has_voice, n_segments_has_no_voice, seconds_has_voice, seconds_has_no_voice, pct_has_voice indicating the number of segments with voice and the duration of the voice/non-voice in the audio}
}
}
\description{
Detect the location of active voice in audio. 
The Voice Activity Detection is implemented using a Gaussian Mixture Model from the "webrtc" framework. 
It works with .wav audio files with a sample rate of 8, 16 or 32 Khz an can be applied over a window of eiher 10, 20 or 30 milliseconds.
}
\examples{
file <- system.file(package = "audio.vadwebrtc", "extdata", "test_wav.wav")
vad  <- VAD(file, mode = "normal", milliseconds = 30)
vad
vad  <- VAD(file, mode = "lowbitrate", milliseconds = 20)
vad
vad  <- VAD(file, mode = "aggressive", milliseconds = 20)
vad
vad  <- VAD(file, mode = "veryaggressive", milliseconds = 20)
vad
vad  <- VAD(file, mode = "normal", milliseconds = 10)
vad
vad$vad_segments

\dontrun{
library(av)
x <- read_audio_bin(file)
plot(seq_along(x) / 16000, x, type = "l")
abline(v = vad$vad_segments$start, col = "red", lwd = 2)
abline(v = vad$vad_segments$end, col = "blue", lwd = 2)

##
## If you have audio which is not in mono or another sample rate
## consider using R package av to convert to the desired format
av_media_info(file)
av_audio_convert(file, output = "audio_pcm_16khz.wav", 
                 format = "wav", channels = 1, sample_rate = 16000)
vad <- VAD("audio_pcm_16khz.wav", mode = "normal")
}

file <- system.file(package = "audio.vadwebrtc", "extdata", "leak-test.wav")
vad  <- VAD(file, mode = "normal")
vad
vad$vad_segments
vad$vad_stats
}
